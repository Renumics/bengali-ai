{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb8eeb0-7d25-4294-9df2-d5786d40b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a9143f-f4d2-4e96-bf95-e08449e789ef",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Bengali.AI Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4fda9e-b645-416f-afb9-0ea51d83fe97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sliceguard\n",
      "  Using cached sliceguard-0.0.10-py3-none-any.whl (17 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "Collecting mutagen\n",
      "  Using cached mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
      "Collecting hnne>=0.1.8\n",
      "  Using cached hnne-0.1.9.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting umap-learn>=0.5.3\n",
      "  Using cached umap-learn-0.5.3.tar.gz (88 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting plotly>=5.15.0\n",
      "  Using cached plotly-5.15.0-py2.py3-none-any.whl (15.5 MB)\n",
      "Collecting scikit-learn>=1.2.2\n",
      "  Using cached scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "Collecting datasets>=2.13.1\n",
      "  Using cached datasets-2.14.2-py3-none-any.whl (518 kB)\n",
      "Collecting torchaudio>=2.0.2\n",
      "  Using cached torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
      "Collecting sentence-transformers>=2.2.1\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy>=1.17.2\n",
      "  Using cached numpy-1.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "Collecting transformers>=4.30.2\n",
      "  Using cached transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "Collecting renumics-spotlight>=1.3.0rc4\n",
      "  Using cached renumics_spotlight-1.3.0rc6-py3-none-any.whl (2.2 MB)\n",
      "Collecting torch>=2.0.1\n",
      "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting Pillow>=9.5.0\n",
      "  Using cached Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Collecting dash>=2.11.1\n",
      "  Using cached dash-2.11.1-py3-none-any.whl (10.4 MB)\n",
      "Collecting fairlearn>=0.8.0\n",
      "  Using cached fairlearn-0.9.0-py3-none-any.whl (231 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Collecting joblib>=0.14\n",
      "  Using cached joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "Collecting scipy>=1.2.0\n",
      "  Using cached scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
      "Collecting audioread>=2.1.9\n",
      "  Using cached audioread-3.0.0-py3-none-any.whl\n",
      "Collecting lazy-loader>=0.1\n",
      "  Using cached lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.venv/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0\n",
      "  Using cached numba-0.57.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.venv/lib/python3.10/site-packages (from librosa) (4.7.1)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
      "Collecting pooch<1.7,>=1.0\n",
      "  Using cached pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "Collecting msgpack>=1.0\n",
      "  Using cached msgpack-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "Collecting soxr>=0.3.2\n",
      "  Using cached soxr-0.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting dash-table==5.0.0\n",
      "  Using cached dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Collecting ansi2html\n",
      "  Using cached ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
      "Collecting dash-html-components==2.0.0\n",
      "  Using cached dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Collecting Flask<2.3.0,>=1.0.4\n",
      "  Using cached Flask-2.2.5-py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.10/site-packages (from dash>=2.11.1->sliceguard) (1.5.7)\n",
      "Collecting dash-core-components==2.0.0\n",
      "  Using cached dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting retrying\n",
      "  Using cached retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from dash>=2.11.1->sliceguard) (2.31.0)\n",
      "Collecting Werkzeug<2.3.0\n",
      "  Using cached Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from datasets>=2.13.1->sliceguard) (6.0.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.14.0\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0\n",
      "  Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from datasets>=2.13.1->sliceguard) (23.1)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Using cached pyarrow-12.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
      "Collecting numpy>=1.17.2\n",
      "  Using cached numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Collecting pynndescent\n",
      "  Using cached pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typer\n",
      "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Collecting cython\n",
      "  Using cached Cython-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0\n",
      "  Using cached llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting appdirs>=1.3.0\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting pycatch22\n",
      "  Using cached pycatch22-0.4.2-cp310-cp310-linux_x86_64.whl\n",
      "Collecting diskcache\n",
      "  Using cached diskcache-5.6.1-py3-none-any.whl (45 kB)\n",
      "Collecting imagecodecs\n",
      "  Using cached imagecodecs-2023.7.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
      "Collecting validators\n",
      "  Using cached validators-0.20.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting websockets\n",
      "  Using cached websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Collecting py-machineid\n",
      "  Using cached py_machineid-0.4.3-py3-none-any.whl (4.4 kB)\n",
      "Collecting pygltflib>=1.15.1\n",
      "  Using cached pygltflib-1.15.6.tar.gz (33 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cleanlab\n",
      "  Using cached cleanlab-2.4.0-py3-none-any.whl (225 kB)\n",
      "Collecting cleanvision\n",
      "  Using cached cleanvision-0.3.2-py3-none-any.whl (54 kB)\n",
      "Collecting orjson\n",
      "  Using cached orjson-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "Collecting importlib_resources<5.8.0\n",
      "  Using cached importlib_resources-5.7.1-py3-none-any.whl (28 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>3.0\n",
      "  Using cached h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Collecting filetype\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from renumics-spotlight>=1.3.0rc4->sliceguard) (3.1.2)\n",
      "Collecting scikit-image\n",
      "  Using cached scikit_image-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\n",
      "Collecting loguru\n",
      "  Using cached loguru-0.7.0-py3-none-any.whl (59 kB)\n",
      "Collecting av\n",
      "  Using cached av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
      "Collecting prettytable\n",
      "  Using cached prettytable-3.8.0-py3-none-any.whl (27 kB)\n",
      "Collecting rsa\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting toml\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.0.7-py3-none-any.whl (138 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.6-py3-none-any.whl (97 kB)\n",
      "Collecting httptools\n",
      "  Using cached httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
      "Collecting uvloop>=0.17.0\n",
      "  Using cached uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "Collecting imageio>=2.18.0\n",
      "  Using cached imageio-2.31.1-py3-none-any.whl (313 kB)\n",
      "Requirement already satisfied: notebook in ./.venv/lib/python3.10/site-packages (from renumics-spotlight>=1.3.0rc4->sliceguard) (7.0.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from renumics-spotlight>=1.3.0rc4->sliceguard) (65.5.0)\n",
      "Collecting trimesh\n",
      "  Using cached trimesh-3.22.5-py3-none-any.whl (682 kB)\n",
      "Collecting fastapi<0.99,>=0.65.2\n",
      "  Using cached fastapi-0.98.0-py3-none-any.whl (56 kB)\n",
      "Collecting aiofiles\n",
      "  Using cached aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pydantic<2.0.0\n",
      "  Using cached pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Collecting databases[aiosqlite]\n",
      "  Using cached databases-0.7.0-py3-none-any.whl (21 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.venv/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.41.0-py3-none-any.whl (64 kB)\n",
      "Collecting cmake\n",
      "  Using cached cmake-3.27.0-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "Collecting lit\n",
      "  Using cached lit-16.0.6-py3-none-any.whl\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Collecting starlette<0.28.0,>=0.27.0\n",
      "  Using cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.13.1->sliceguard) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.13.1->sliceguard) (3.2.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->renumics-spotlight>=1.3.0rc4->sliceguard) (2.1.3)\n",
      "Collecting dataclasses-json>=0.0.25\n",
      "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
      "Collecting deprecated\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->dash>=2.11.1->sliceguard) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->dash>=2.11.1->sliceguard) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->dash>=2.11.1->sliceguard) (2023.7.22)\n",
      "Collecting termcolor>=2.0.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting matplotlib>=3.4\n",
      "  Using cached matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Collecting imagehash>=4.2.0\n",
      "  Using cached ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "Collecting tabulate>=0.8.3\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting sqlalchemy<1.5,>=1.4.42\n",
      "  Using cached SQLAlchemy-1.4.49-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Collecting aiosqlite\n",
      "  Using cached aiosqlite-0.19.0-py3-none-any.whl (15 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.7\n",
      "  Using cached jupyterlab_widgets-3.0.8-py3-none-any.whl (214 kB)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (8.14.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (6.25.0)\n",
      "Collecting widgetsnbextension~=4.0.7\n",
      "  Using cached widgetsnbextension-4.0.8-py3-none-any.whl (2.3 MB)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (5.9.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in ./.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.24.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.7.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in ./.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (6.3.2)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in ./.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.2.3)\n",
      "Requirement already satisfied: jupyterlab<5,>=4.0.2 in ./.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (4.0.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prettytable->renumics-spotlight>=1.3.0rc4->sliceguard) (0.2.6)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Using cached PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Using cached tifffile-2023.7.18-py3-none-any.whl (221 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (1.6.7)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (0.1.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (8.3.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (0.1.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (5.3.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in ./.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (25.1.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (0.6.2)\n",
      "Requirement already satisfied: backcall in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (0.19.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (2.15.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (3.0.39)\n",
      "Requirement already satisfied: overrides in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (7.3.1)\n",
      "Requirement already satisfied: prometheus-client in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.17.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (3.7.1)\n",
      "Requirement already satisfied: websocket-client in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.6.1)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (5.9.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.17.1)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (7.7.3)\n",
      "Requirement already satisfied: send2trash in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.8.2)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.4.4)\n",
      "Requirement already satisfied: argon2-cffi in ./.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (21.3.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<5,>=4.0.2->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.2.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab<5,>=4.0.2->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.0.4)\n",
      "Requirement already satisfied: tomli in ./.venv/lib/python3.10/site-packages (from jupyterlab<5,>=4.0.2->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.0.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.9.14)\n",
      "Requirement already satisfied: babel>=2.10 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.17.3 in ./.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (4.18.4)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (613 kB)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Using cached wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (0.8.3)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.30.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.9.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2023.7.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (3.10.0)\n",
      "Requirement already satisfied: rfc3339-validator in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.1.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./.venv/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.0.7)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.7.1)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (3.0.1)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (6.0.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.8.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (4.12.2)\n",
      "Requirement already satisfied: tinycss2 in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.2.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.2.2)\n",
      "Requirement already satisfied: fastjsonschema in ./.venv/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.18.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (0.7.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./.venv/lib/python3.10/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (21.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->renumics-spotlight>=1.3.0rc4->sliceguard) (1.2.0)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (0.5.1)\n",
      "Requirement already satisfied: fqdn in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.4)\n",
      "Requirement already satisfied: uri-template in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in ./.venv/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (2.4.1)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./.venv/lib/python3.10/site-packages (from isoduration->jsonschema>=4.17.3->jupyterlab-server<3,>=2.22.1->notebook->renumics-spotlight>=1.3.0rc4->sliceguard) (1.2.3)\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, pytz, pycatch22, py-machineid, msgpack, mpmath, lit, filetype, dash-table, dash-html-components, dash-core-components, cmake, av, appdirs, xxhash, wrapt, widgetsnbextension, wheel, Werkzeug, websockets, validators, uvloop, tzdata, tqdm, toml, threadpoolctl, termcolor, tenacity, tabulate, sympy, retrying, regex, pyparsing, pydantic, pyasn1, prettytable, Pillow, orjson, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, numpy, networkx, mypy-extensions, mutagen, multidict, marshmallow, loguru, llvmlite, lazy-loader, kiwisolver, jupyterlab-widgets, joblib, itsdangerous, importlib_resources, httptools, h11, greenlet, fsspec, frozenlist, fonttools, filelock, diskcache, dill, cython, cycler, click, audioread, async-timeout, ansi2html, aiosqlite, aiofiles, yarl, uvicorn, typing-inspect, typer, trimesh, tifffile, starlette, sqlalchemy, soxr, soundfile, scipy, rsa, PyWavelets, pyarrow, pooch, plotly, pandas, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numba, nltk, multiprocess, imageio, imagecodecs, huggingface-hub, h5py, Flask, deprecated, contourpy, aiosignal, transformers, scikit-learn, scikit-image, nvidia-cusolver-cu11, nvidia-cudnn-cu11, matplotlib, imagehash, fastapi, dataclasses-json, databases, dash, aiohttp, pynndescent, pygltflib, librosa, fairlearn, cleanvision, cleanlab, umap-learn, ipywidgets, hnne, datasets, renumics-spotlight, triton, torch, torchvision, torchaudio, sentence-transformers, sliceguard\n",
      "\u001b[33m  DEPRECATION: validators is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for validators ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: pynndescent is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25h  Running setup.py install for pynndescent ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: pygltflib is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25h  Running setup.py install for pygltflib ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: umap-learn is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25h  Running setup.py install for umap-learn ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: hnne is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25h  Running setup.py install for hnne ... \u001b[?25ldone\n",
      "\u001b[33m  DEPRECATION: sentence-transformers is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25h  Running setup.py install for sentence-transformers ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Flask-2.2.5 Pillow-10.0.0 PyWavelets-1.4.1 Werkzeug-2.2.3 aiofiles-23.1.0 aiohttp-3.8.5 aiosignal-1.3.1 aiosqlite-0.19.0 ansi2html-1.8.0 appdirs-1.4.4 async-timeout-4.0.2 audioread-3.0.0 av-10.0.0 cleanlab-2.4.0 cleanvision-0.3.2 click-8.1.6 cmake-3.27.0 contourpy-1.1.0 cycler-0.11.0 cython-3.0.0 dash-2.11.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 databases-0.7.0 dataclasses-json-0.5.14 datasets-2.14.2 deprecated-1.2.14 dill-0.3.7 diskcache-5.6.1 fairlearn-0.9.0 fastapi-0.98.0 filelock-3.12.2 filetype-1.2.0 fonttools-4.41.1 frozenlist-1.4.0 fsspec-2023.6.0 greenlet-2.0.2 h11-0.14.0 h5py-3.9.0 hnne-0.1.9 httptools-0.6.0 huggingface-hub-0.16.4 imagecodecs-2023.7.10 imagehash-4.3.1 imageio-2.31.1 importlib_resources-5.7.1 ipywidgets-8.0.7 itsdangerous-2.1.2 joblib-1.3.1 jupyterlab-widgets-3.0.8 kiwisolver-1.4.4 lazy-loader-0.3 librosa-0.10.0.post2 lit-16.0.6 llvmlite-0.40.1 loguru-0.7.0 marshmallow-3.20.1 matplotlib-3.7.2 mpmath-1.3.0 msgpack-1.0.5 multidict-6.0.4 multiprocess-0.70.15 mutagen-1.46.0 mypy-extensions-1.0.0 networkx-3.1 nltk-3.8.1 numba-0.57.1 numpy-1.22.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 orjson-3.9.2 pandas-2.0.3 plotly-5.15.0 pooch-1.6.0 prettytable-3.8.0 py-machineid-0.4.3 pyarrow-12.0.1 pyasn1-0.5.0 pycatch22-0.4.2 pydantic-1.10.12 pygltflib-1.15.6 pynndescent-0.5.10 pyparsing-3.0.9 pytz-2023.3 regex-2023.6.3 renumics-spotlight-1.3.0rc6 retrying-1.3.4 rsa-4.9 safetensors-0.3.1 scikit-image-0.21.0 scikit-learn-1.3.0 scipy-1.11.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 sliceguard-0.0.10 soundfile-0.12.1 soxr-0.3.5 sqlalchemy-1.4.49 starlette-0.27.0 sympy-1.12 tabulate-0.9.0 tenacity-8.2.2 termcolor-2.3.0 threadpoolctl-3.2.0 tifffile-2023.7.18 tokenizers-0.13.3 toml-0.10.2 torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2 tqdm-4.65.0 transformers-4.31.0 trimesh-3.22.5 triton-2.0.0 typer-0.9.0 typing-inspect-0.9.0 tzdata-2023.3 umap-learn-0.5.3 uvicorn-0.23.2 uvloop-0.17.0 validators-0.20.0 websockets-11.0.3 wheel-0.41.0 widgetsnbextension-4.0.8 wrapt-1.15.0 xxhash-3.3.0 yarl-1.9.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install these dependencies\n",
    "!pip install -U sliceguard pandas mutagen tqdm librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6d4a78-4499-49c6-a712-80f5168df2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports you will need\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import librosa\n",
    "from mutagen.mp3 import MP3\n",
    "\n",
    "# from renumics import spotlight\n",
    "# from renumics.spotlight import Audio, Embedding\n",
    "# from sliceguard import SliceGuard\n",
    "from sliceguard.embeddings import generate_audio_embeddings, generate_text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee4315f-07dd-4c80-9755-cd0a1af9ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the path to your dataset here\n",
    "DATASET_DIR = \"/home/daniel/data/bengaliai/bengaliai-speech\"\n",
    "dataset_dir = Path(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2bc5ae-c0c4-49e4-9107-b982b7a68e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(dataset_dir / \"train.csv\")\n",
    "# Generate the audio paths\n",
    "df[\"path\"] = str(dataset_dir / \"train_mp3s\") + \"/\" + df[\"id\"] + \".mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ad6806-0434-41a9-81f7-fe5c92a4c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just for running the code more quickly in dev\n",
    "# df = df.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e50d58-9454-40f1-8a34-a7504b863809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963636"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8490ebf-0bac-4b23-8cb0-9d062ebf954f",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d7fbc1-83a3-47a4-ab9a-74dfb9148ddc",
   "metadata": {},
   "source": [
    "## Simple Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f9260a-9241-48a3-a393-9f996ce3c5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 298/963636 [00:03<2:58:52, 89.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m tqdm(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m], total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[1;32m     10\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(p)\n\u001b[0;32m---> 11\u001b[0m     rms \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrms\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     rms_means\u001b[38;5;241m.\u001b[39mappend(rms\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     13\u001b[0m     rms_maxs\u001b[38;5;241m.\u001b[39mappend(rms\u001b[38;5;241m.\u001b[39mmax())\n",
      "File \u001b[0;32m~/code/bengali-ai/.venv/lib/python3.10/site-packages/librosa/feature/spectral.py:887\u001b[0m, in \u001b[0;36mrms\u001b[0;34m(y, S, frame_length, hop_length, center, pad_mode, dtype)\u001b[0m\n\u001b[1;32m    884\u001b[0m     x \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mframe(y, frame_length\u001b[38;5;241m=\u001b[39mframe_length, hop_length\u001b[38;5;241m=\u001b[39mhop_length)\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# Calculate power\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     power \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;66;03m# Check the frame length\u001b[39;00m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m S\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m!=\u001b[39m frame_length \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/code/bengali-ai/.venv/lib/python3.10/site-packages/librosa/util/utils.py:2521\u001b[0m, in \u001b[0;36mabs2\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m   2518\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m y\u001b[38;5;241m.\u001b[39mastype(dtype)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2520\u001b[0m     \u001b[38;5;66;03m# suppress type check, mypy doesn't know this is real\u001b[39;00m\n\u001b[0;32m-> 2521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Simple audio features\n",
    "\n",
    "# Audio level\n",
    "rms_means = []\n",
    "rms_maxs = []\n",
    "rms_stds = []\n",
    "spectral_flatness_means = []\n",
    "audio_lengths = []\n",
    "for p in tqdm(df[\"path\"], total=len(df)):\n",
    "    y, sr = librosa.load(p)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    rms_means.append(rms.mean())\n",
    "    rms_maxs.append(rms.max())\n",
    "    rms_stds.append(rms.std())\n",
    "    spectral_flatness_means.append(librosa.feature.spectral_flatness(y=y).mean())\n",
    "    audio_lengths.append(y.shape[0] / sr)\n",
    "\n",
    "df[\"audio_rms_mean\"] = rms_means\n",
    "df[\"audio_rms_max\"] = rms_maxs\n",
    "df[\"audio_rms_std\"] = rms_stds\n",
    "df[\"audio_spectral_flatness_mean\"] = spectral_flatness_means\n",
    "df[\"audio_length_s\"] = audio_lengths\n",
    "\n",
    "# df.to_json(\"bengali_ai_features_scalar.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427817f-6c60-406a-b16b-99eeb599dd0a",
   "metadata": {},
   "source": [
    "## Audio Embedding Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c70e37-ffaa-468b-95fa-11c706e1d2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 000_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc498a0825b45cc8bff26efc077e7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 001_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d646a1872a341b2b2d9b9abc428576d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 002_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad94e6bc57945d7bbdb450ab0fec53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 003_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b3496916554ae0a2c9d951c04704a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 004_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcd031b657449e4a388731aa6e02462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 005_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2bc99b90a64ecc8bca39370d062fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 006_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4b97eeca8642c9887ca088c4d5fb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 007_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fde432fdac04709a879f25bbc2c54f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 008_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4bbb15bc8e4318bb23df238d43d78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 009_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69fc0190ea945dab69e77e072045997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 010_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243797530bcd414e9cb3db24debdae82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 011_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1911f69057374e75985e893205451dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 012_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4518b15e80f45de8c4fe14480fd8271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 013_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81912d2f4b824f7ebac6b93dc44e9c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 014_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa88c38996548bc98a4c7452d7af6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 015_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50eb773cc464d1d814b26c0971866d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 016_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2dd80aab3a445c8c59382f075d5cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 017_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509ec8dd496d48ed9a72bc16ecdf528c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 018_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fcde069de346d9ba4c44b9fc512172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 019_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a991f451b50481ba35bf8dff12a30d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 020_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b42a2214585481690984529b0c1085f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 021_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26105cf3fd7e471ba941f904b02bc46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 022_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23b2871caf24787a43adea71345f000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 023_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79aa975d6b7a4e37a71fd92aafab33d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 024_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52650b2cbfb42089bd2048fa8dedfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 025_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3de860b7674396afefdb1198255e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 026_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cff20170d54b119c977e2118cdd1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 027_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d6fa55ebd74311b049f6773e8d4bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 028_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828cdda7bb2d406cb476abbdc850465a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 029_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c1453a244543dd8771bb63d6a390b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 030_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c300e4c7a6ea4bd8a45b4be11c17e8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 031_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6dcf012755416eb596bb8743d7ca28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 032_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866f2d0a4c9d419e8629b8ad6401f5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 033_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea5d2116796481a9a255efdad0cf3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 034_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e080bd1ce147aca23badcb70652619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 035_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117e19736556481f9eb31448a98dd302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 036_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edde725a54d4569a430909b64fa0e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 037_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ba072fc33c4da1867bdc8010e6fbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 038_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf332ed6fca476b8394a5576ee918ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 039_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17d68d43b464f0dada1937c389b0144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 040_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8131f454434876a3450a49118ea223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 041_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883402ebca3447a0a1206d4386129abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 042_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9208101485d4bc3bfabe4efaa8ee3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 043_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0bf8f20b9048c5afe027af5393cc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 044_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e715c4ceef94f6f96a98679da0c8a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 045_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e692453bf7ff47dabd13772eafd4585a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 046_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12ae237a4fb4c54981d4d97132f34da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 047_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c87fc2037da424ba58c9eb9009ea6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 048_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bf435df9f64e1a9b0447a6f1836411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 049_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fdecaf044842b2b01276f748e571cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 050_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4ac4bbe49048268c2fd6e93ebec8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 051_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64960df32364edab4134535453a3bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 052_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07497d152b145d1ab6fb987ca080431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 053_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa439965a5014c188e6b28810eff45f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 054_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264d6086e63a456d99e0b8b765f299a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 055_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9961299d2d444c9d6044db7edcaf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 056_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0df74915c754abfa56559e54375d00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 057_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9ee7323e424496a754d10913a16185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 058_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd489a14a5df47a9badd2582454e1fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 059_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac090d3a175b4fb2bc424485cfe7a022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 060_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bde67c369e470c9d5fb13c552ee37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 061_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452d40d6b84749d4872ed17df0afdaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 062_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a3b86ffa054441ab1bc8f2dad05a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 063_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474b9df529614d64a2c10175331caba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 064_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e1daeb354040989357c46797246a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 065_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87955729db54d3d8cb3bcebe896eefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 066_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bff3e261624a1aaa78ab9851443a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 067_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbd44cf8ef14a93bf0766d3753c9bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 068_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da297c69c804069a00d13801af13c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 069_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becfa2ba171d41608f77c26cf33bcf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 070_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d7b56c26da4d069adc03d1aa2f4ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 071_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c87a22932c48f6b42e5fa57622c945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 072_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4cce2c86794576ae41b0d43d5bac42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 073_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1b8a98a2dd41809ba2a99155ba0ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 074_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c3e7f0a7d242ae9ed6a72959463754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 075_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20d2a147a4647eea6bbd817054f0559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 076_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d422dd5bb7499193683d6391b6996b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 077_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a374bdceb8404766be31b0c72f1f5c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 078_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f85efa0754f4840845bd93ef92a64e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 079_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80038657c928461e9678315b1e0d1bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 080_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cc201f00c641ba9dbe049a0010e5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 081_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49241995afc249cabf4f3be6c461b7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 082_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8bda9c39c24bbf9a3b02b2330f7110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 083_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079223f24ca04fe8a0d540ca81bd816a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 084_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcf0e1285ef49609aed759ce2065185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 085_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d36cd558c447a184aa0e8e0efe5685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 086_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1990c76aba1f4c88a24fa47c67244cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 087_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e87491e86c2478a85e48d362ef5c5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 088_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457c392140164811a721f5a23e3b0fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 089_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403c722caec449388810719df9133724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 090_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081d85ad67c2405b820b31805b175d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 091_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94578a7e08494f47a29039802d1fb3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 092_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e0de9aaaf94099a4ce881a8585fca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 093_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7249afae081f4ea08f0b2b98fb813486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 094_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bbad2ea0ad4296a6eda92a43c99dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 095_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298120375067416980ba85cf80c16ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 096_audio_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d65e59fcf1b48b190c3be7925c24203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3636 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# audio_embeddings = generate_audio_embeddings(df[\"path\"].values)\n",
    "\n",
    "# with open(\"audio_embeddings.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(audio_embeddings, f)\n",
    "chunk_size = 10000\n",
    "\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    chunk_id = i // chunk_size\n",
    "    chunk_file = f\"{chunk_id:03d}_audio_embeddings.pkl\"\n",
    "    print(f\"Generating {chunk_file}...\")\n",
    "    if not Path(chunk_file).is_file():\n",
    "        chunk_audio_embeddings = generate_audio_embeddings(df[\"path\"].values[i:i+chunk_size])\n",
    "        with open(chunk_file, \"wb\") as f:\n",
    "            pickle.dump(chunk_audio_embeddings, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c5b898-885e-4c5c-8b32-693a2943f4fc",
   "metadata": {},
   "source": [
    "## Text Embedding Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba60379d-fbf2-4965-9d2b-5c5f2f4d3383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 000_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 001_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 002_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 003_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 004_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 005_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 006_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 007_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 008_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 009_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 010_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 011_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 012_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 013_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 014_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 015_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 016_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 017_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 018_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 019_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 020_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 021_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 022_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 023_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 024_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 025_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 026_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 027_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 028_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 029_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 030_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 031_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 032_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 033_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 034_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 035_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 036_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 037_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 038_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 039_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 040_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 041_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 042_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 043_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 044_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 045_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 046_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 047_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 048_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 049_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 050_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 051_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 052_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 053_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 054_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 055_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 056_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 057_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 058_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 059_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 060_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 061_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 062_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 063_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 064_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 065_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 066_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 067_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 068_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 069_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 070_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 071_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 072_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 073_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 074_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 075_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 076_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 077_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 078_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 079_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 080_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 081_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 082_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 083_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 084_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 085_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 086_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 087_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 088_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 089_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 090_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 091_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 092_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 093_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 094_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 095_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n",
      "Generating 096_text_embeddings.pkl...\n",
      "Embedding computation on cuda with batch size 1 and multiprocessing None.\n"
     ]
    }
   ],
   "source": [
    "# text_embeddings = generate_text_embeddings(df[\"sentence\"].values)\n",
    "\n",
    "# with open(\"text_embeddings.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(text_embeddings, f)\n",
    "\n",
    "chunk_size = 10000\n",
    "\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    chunk_id = i // chunk_size\n",
    "    chunk_file = f\"{chunk_id:03d}_text_embeddings.pkl\"\n",
    "    print(f\"Generating {chunk_file}...\")\n",
    "    if not Path(chunk_file).is_file():\n",
    "        chunk_text_embeddings = generate_text_embeddings(df[\"sentence\"].values[i:i+chunk_size])\n",
    "        with open(chunk_file, \"wb\") as f:\n",
    "            pickle.dump(chunk_text_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f1fb3-3d6a-4fd5-8bf1-9dd72a81bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"audio_embedding\"] = [e.tolist() for e in audio_embeddings]\n",
    "df[\"text_embedding\"] = [e.tolist() for e in text_embeddings]\n",
    "\n",
    "df.to_json(\"bengali_ai_features.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc493811-b428-4b9f-9f77-0b8524f95b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 000_text_embeddings.pkl...\n",
      "Loading 001_text_embeddings.pkl...\n",
      "Loading 002_text_embeddings.pkl...\n",
      "Loading 003_text_embeddings.pkl...\n",
      "Loading 004_text_embeddings.pkl...\n",
      "Loading 005_text_embeddings.pkl...\n",
      "Loading 006_text_embeddings.pkl...\n",
      "Loading 007_text_embeddings.pkl...\n",
      "Loading 008_text_embeddings.pkl...\n",
      "Loading 009_text_embeddings.pkl...\n",
      "Loading 010_text_embeddings.pkl...\n",
      "Loading 011_text_embeddings.pkl...\n",
      "Loading 012_text_embeddings.pkl...\n",
      "Loading 013_text_embeddings.pkl...\n",
      "Loading 014_text_embeddings.pkl...\n",
      "Loading 015_text_embeddings.pkl...\n",
      "Loading 016_text_embeddings.pkl...\n",
      "Loading 017_text_embeddings.pkl...\n",
      "Loading 018_text_embeddings.pkl...\n",
      "Loading 019_text_embeddings.pkl...\n",
      "Loading 020_text_embeddings.pkl...\n",
      "Loading 021_text_embeddings.pkl...\n",
      "Loading 022_text_embeddings.pkl...\n",
      "Loading 023_text_embeddings.pkl...\n",
      "Loading 024_text_embeddings.pkl...\n",
      "Loading 025_text_embeddings.pkl...\n",
      "Loading 026_text_embeddings.pkl...\n",
      "Loading 027_text_embeddings.pkl...\n",
      "Loading 028_text_embeddings.pkl...\n",
      "Loading 029_text_embeddings.pkl...\n",
      "Loading 030_text_embeddings.pkl...\n",
      "Loading 031_text_embeddings.pkl...\n",
      "Loading 032_text_embeddings.pkl...\n",
      "Loading 033_text_embeddings.pkl...\n",
      "Loading 034_text_embeddings.pkl...\n",
      "Loading 035_text_embeddings.pkl...\n",
      "Loading 036_text_embeddings.pkl...\n",
      "Loading 037_text_embeddings.pkl...\n",
      "Loading 038_text_embeddings.pkl...\n",
      "Loading 039_text_embeddings.pkl...\n",
      "Loading 040_text_embeddings.pkl...\n",
      "Loading 041_text_embeddings.pkl...\n",
      "Loading 042_text_embeddings.pkl...\n",
      "Loading 043_text_embeddings.pkl...\n",
      "Loading 044_text_embeddings.pkl...\n",
      "Loading 045_text_embeddings.pkl...\n",
      "Loading 046_text_embeddings.pkl...\n",
      "Loading 047_text_embeddings.pkl...\n",
      "Loading 048_text_embeddings.pkl...\n",
      "Loading 049_text_embeddings.pkl...\n",
      "Loading 050_text_embeddings.pkl...\n",
      "Loading 051_text_embeddings.pkl...\n",
      "Loading 052_text_embeddings.pkl...\n",
      "Loading 053_text_embeddings.pkl...\n",
      "Loading 054_text_embeddings.pkl...\n",
      "Loading 055_text_embeddings.pkl...\n",
      "Loading 056_text_embeddings.pkl...\n",
      "Loading 057_text_embeddings.pkl...\n",
      "Loading 058_text_embeddings.pkl...\n",
      "Loading 059_text_embeddings.pkl...\n",
      "Loading 060_text_embeddings.pkl...\n",
      "Loading 061_text_embeddings.pkl...\n",
      "Loading 062_text_embeddings.pkl...\n",
      "Loading 063_text_embeddings.pkl...\n",
      "Loading 064_text_embeddings.pkl...\n",
      "Loading 065_text_embeddings.pkl...\n",
      "Loading 066_text_embeddings.pkl...\n",
      "Loading 067_text_embeddings.pkl...\n",
      "Loading 068_text_embeddings.pkl...\n",
      "Loading 069_text_embeddings.pkl...\n",
      "Loading 070_text_embeddings.pkl...\n",
      "Loading 071_text_embeddings.pkl...\n",
      "Loading 072_text_embeddings.pkl...\n",
      "Loading 073_text_embeddings.pkl...\n",
      "Loading 074_text_embeddings.pkl...\n",
      "Loading 075_text_embeddings.pkl...\n",
      "Loading 076_text_embeddings.pkl...\n",
      "Loading 077_text_embeddings.pkl...\n",
      "Loading 078_text_embeddings.pkl...\n",
      "Loading 079_text_embeddings.pkl...\n",
      "Loading 080_text_embeddings.pkl...\n",
      "Loading 081_text_embeddings.pkl...\n",
      "Loading 082_text_embeddings.pkl...\n",
      "Loading 083_text_embeddings.pkl...\n",
      "Loading 084_text_embeddings.pkl...\n",
      "Loading 085_text_embeddings.pkl...\n",
      "Loading 086_text_embeddings.pkl...\n",
      "Loading 087_text_embeddings.pkl...\n",
      "Loading 088_text_embeddings.pkl...\n",
      "Loading 089_text_embeddings.pkl...\n",
      "Loading 090_text_embeddings.pkl...\n",
      "Loading 091_text_embeddings.pkl...\n",
      "Loading 092_text_embeddings.pkl...\n",
      "Loading 093_text_embeddings.pkl...\n",
      "Loading 094_text_embeddings.pkl...\n",
      "Loading 095_text_embeddings.pkl...\n",
      "Loading 096_text_embeddings.pkl...\n"
     ]
    }
   ],
   "source": [
    "all_text_embeddings = []\n",
    "\n",
    "chunk_size = 10000\n",
    "\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    chunk_id = i // chunk_size\n",
    "    chunk_file = f\"{chunk_id:03d}_text_embeddings.pkl\"\n",
    "    print(f\"Loading {chunk_file}...\")\n",
    "    with open(chunk_file, \"rb\") as f:\n",
    "        chunk_text_embeddings = pickle.load(f)\n",
    "    all_text_embeddings.append(chunk_text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6133de9b-1ec7-4a30-8634-c73547b2c12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 000_audio_embeddings.pkl...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '000_audio_embeddings.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m chunk_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_id\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_audio_embeddings.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     chunk_audio_embeddings \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     11\u001b[0m all_audio_embeddings\u001b[38;5;241m.\u001b[39mappend(chunk_audio_embeddings)\n",
      "File \u001b[0;32m~/code/bengali-ai/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '000_audio_embeddings.pkl'"
     ]
    }
   ],
   "source": [
    "all_audio_embeddings = []\n",
    "\n",
    "chunk_size = 10000\n",
    "\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    chunk_id = i // chunk_size\n",
    "    chunk_file = f\"{chunk_id:03d}_audio_embeddings.pkl\"\n",
    "    print(f\"Loading {chunk_file}...\")\n",
    "    with open(chunk_file, \"rb\") as f:\n",
    "        chunk_audio_embeddings = pickle.load(f)\n",
    "    all_audio_embeddings.append(chunk_audio_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93160220-1661-479a-bd32-e027c70f3ecd",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b6e2e-fb47-4809-90fa-5e9e6c5bd2f4",
   "metadata": {},
   "source": [
    "## Load the Feature-enriched Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3021850-c139-49ea-95f2-5ea564a95fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"bengali_ai_features.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b450cd12-ea4e-4b19-a735-f1f5b38d9fef",
   "metadata": {},
   "source": [
    "## Basics about the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff6630-b653-432b-860c-4c4ef2de6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample count and columns\n",
    "print(f\"Sample count is {len(df)}.\")\n",
    "print(f\"Dataframe contains the columns {df.columns.tolist()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b39540-dd23-4d93-bcb6-8fbe7c5266a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ratio\n",
    "print(\"##### Distribution between splits #####\")\n",
    "px.histogram(df, x=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb15d1-04e8-4f84-a381-d093d6ca6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates\n",
    "print(\"##### Distribution on exact duplicates #####\")\n",
    "px.histogram(df[\"sentence\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a29c4-0448-4cb5-9396-cff1359219a6",
   "metadata": {},
   "source": [
    "## Simple Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15c5be-f01e-4411-b4af-a976552cda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"##### Distribution of audio lengths #####\")\n",
    "audio_length_fig = px.histogram(df, x=\"audio_length_s\")\n",
    "audio_length_fig.show()\n",
    "\n",
    "print(\"##### Distribution of rms means #####\")\n",
    "audio_rms_means_fig = px.histogram(df, x=\"audio_rms_mean\")\n",
    "audio_rms_means_fig.show()\n",
    "\n",
    "print(\"##### Distribution of rms maxs #####\")\n",
    "audio_rms_maxs_fig = px.histogram(df, x=\"audio_rms_max\")\n",
    "audio_rms_maxs_fig.show()\n",
    "\n",
    "print(\"##### Distribution of rms stds #####\")\n",
    "audio_rms_stds_fig = px.histogram(df, x=\"audio_rms_std\")\n",
    "audio_rms_stds_fig.show()\n",
    "\n",
    "\n",
    "print(\"##### Distribution of spectral flatness #####\")\n",
    "audio_spectral_flatness_fig = px.histogram(df, x=\"audio_spectral_flatness_mean\")\n",
    "audio_spectral_flatness_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f6a0f-302d-41a0-ba84-4caa35a24f90",
   "metadata": {},
   "source": [
    "## Audio Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c5d93-7631-4f46-a495-04c29c9478a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SliceGuard()\n",
    "sg.show(df, [\"audio_embedding\"], precomputed_embeddings={\"audio_embedding\": np.vstack(df[\"audio_embedding\"])}, drop_reference=\"parent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be24cf34-7750-4767-af4f-3f9e03583e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SliceGuard()\n",
    "sg.find_issues(df, [\"audio_embedding\"], min_drop=0.02, min_support=5, drop_reference=\"parent\", precomputed_embeddings={\"audio_embedding\": np.vstack(df[\"audio_embedding\"])})\n",
    "sg.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3f006-3c20-465c-99db-63dcd7f8beed",
   "metadata": {},
   "source": [
    "## Text Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72889d71-def2-4a5d-b8fe-dd4086773b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SliceGuard()\n",
    "sg.show(df, [\"text_embedding\"], precomputed_embeddings={\"text_embedding\": np.vstack(df[\"text_embedding\"])}, drop_reference=\"parent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61f130-50a1-4a23-82ef-1a78ce6b1e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SliceGuard()\n",
    "sg.find_issues(df, [\"text_embedding\"], min_drop=0.1, min_support=10, precomputed_embeddings={\"text_embedding\": np.vstack(df[\"text_embedding\"])}, drop_reference=\"parent\")\n",
    "sg.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9545b-1cb9-492c-b4cd-916d73e044ec",
   "metadata": {},
   "source": [
    "# Free EDA in Spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e86af2-94b3-48dd-ac5c-12e3cd723ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotlight.show(df, dtype={\"audio_embedding\": Embedding, \"text_embedding\": Embedding, \"path\": Audio})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
